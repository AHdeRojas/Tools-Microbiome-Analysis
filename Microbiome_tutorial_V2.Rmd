---
title: "Microbial diversity analysis using R tools"
author: "Sudarshan A. Shetty and Gerben D A Hermes"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: true
    use_bookdown: false
    highlight: haddock
---


<center>![ microbiome R package](N:/MOLECO/R_for_Microbial_Ecology/R_for_NG_Tax_Sept2017/microbiomeR_Stickerreseize.png)</center>   



**This the microbial diversity analysis tutorial (Version 2.0)**

# Introduction

This is a simplified version of various methods available these days to microbial ecologists. The ideology of putting all of this together is to share the information and also clarify the 'ease'(you see we didn't say 'simple') of using R-software and related packages. The analyses shown here are basic and aimed mostly at introducing the reader to commonly used packages, scripts and data analysis methods. Descision making related to different parameters will still be soley upon the user, although output generated using NG-Tax will generally need very little polishing, depending on the settings that were used. It is advised that the reader does adequate referencing for each of the features and makes better choices on the methods, etc. during the analysis of his/her data, based on the biological question.

The main tools used here are [Phyloseq](https://joey711.github.io/phyloseq/) and [microbiome](http://microbiome.github.io/microbiome/)


**Important Note 1**:

**Wisdom1** - There is no substitute for careful reading, so read the tutorial first and then start playing with it. **Wisdom2** - never skip a step or piece of text, you might need a file that was generated previously. **Wisdom 3** - If it took the authors weeks to make this tutorial don't expect to grasp it in one afternoon. Take your time and don't rush.

Kindly cite all the packages and tools that you have used in your analysis. Also make sure that you provide the scripts you used for anlaysis as a supplementary material with your research article.    
You can also find useful cheat sheets for R in the folder Useful "Useful R cheat sheets".  
or other simple commands on plotting or data transformation on [Quick-R](http://www.statmethods.net/)   
============================================================================================ 

Here, we use data from **Mock Communities (MCs)** used to benchmark the **NG-Tax pipeline.** These MCs are synthetic communities of known composition.  It represents data from 3 different Hiseq runs spread over 7 libraries with two different primers covering region V4 (F515-R806) and V5-V6 (F784-R1064) and different PCR settings (25,30 and 35 cycles and pooling of triplicate PCR reactions or a single one). More information with regards to PCR settings and generation of the data can be found here:[NG-Tax](https://f1000research.com/articles/5-1791/v1#DS0). For other published test datasets you can check [Qiita](https://qiita.ucsd.edu)    

Location of test files: `N:/MOLECO/R_for_Microbial_Ecology/R_for_NG_Tax_May2017/Input_files`  

Therefore, this data will alow you to compare what you sequenced to perfect error free data and see how well your sequenced data can reproduce the theoretical composition and underlying biological signals.  

**COPY COMPLETE FOLDER ON YOUR PERSONAL DIRVE. DO NOT MAKE ANY CHANGES TO THE FILES IN N-DRIVE.** 

In our lab the commonly used tool for OTU picking is [NG-Tax](https://f1000research.com/articles/5-1791/v1#DS0). This approach removes a lot of spurious OTUs arising from PCR and sequencing errors. Although, based on the analysis of the positive controls (Mock Communities) further filtering or data transformations might be necessary. This small tutorial aims to provide tools on which to base these decisions.  

## An outline of the basic steps:

1. Import OTU table/Biom file, metadata, tree files into R using the Phyloseq package.   

**NOTE**  
A new function `read_phyloseq` has been created in Microbiome package, please update to the latest version for easy creation of phyloseq object.    

2. Pre-proccessing of the phyloseq object.  
3. Alpha diversity analysis   
4. Beta diveristy analysis (unconstrained, constrained and with and without rarefaction).  
5. Other useful R packages.  

# Loading the libraries/packages  

**These are necessary to run the commands**
If you are setting up RStudio for the first time you need to install a wide range of so-called R-packages. This can be found in the file `required_packages.R` in the `N:/MOLECO/R_for_Microbial_Ecology/R_for_NG_Tax_May2017/Input_files` folder.  

You may need to do some changes and this might be specific for your PC. Read the `required_packages.R` file properly.  

  
```{r load libraries, warning = FALSE, message = FALSE}
#Load the required packages
library(ggplot2)
library(ape)
library(plyr)
library(vegan)
library(Biostrings)
library(RColorBrewer)
library(reshape2)
library(scales)
library(data.table)
library(DESeq2) # in case you want to use negative binomial for differential OTU analysis
library(microbiome)
library(dplyr)
library(phyloseq)
library(DT) #for interactive tables
library(Rcpp)
```

To run this example you will need three files. These are stored in folder located at this path `N:/MOLECO/R_for_Microbial_Ecology/R_for_NG_Tax_May2017`. Create a folder in your personal computer and copy the `NGTaxMerged_conv.biom`, `mappingMerged_edit.csv` and `combinedTree.tre` files in it. Then set the working directory to this folder using the following command.  
**Kindly read the "README.txt" file**.    

```{r}

# setwd("D:/path/to/your/folder")
# Example of how to set the working directory 
# setwd("N:/MOLECO/R_for_Microbial_Ecology/R_for_NG_Tax_May2017")

# remember the path in windows is given as "\" however for R it has to be changed to "/".  

```

When you are working on your own data kindly check that:  

If you have the mapping file in .txt format then open it in excel and save it as CSV(comma delimited) ".csv". Also good to renames samples column from "#SampleID" to "SampleID". Remove the # sign. Do not keep any special characters like #,$ and also spaces etc. use underscore "_" to seperate two words for eg. SampleID can also be written as Sample_ID.      

```{r}

# Set plotting theme
# This will determine the overall look of your plots. Other themes are available in the ggplot2 package
theme_set(theme_bw())

```

# Making a phyloseq object

This is the basis for your analyses. In this phyloseq object, information on OTUs, taxonomy, the phylogenetic tree and metadata is stored. A single object with all this information provides a very convinient way of handling data.
Please remember that the metadata (i.e. mapping) file has to be in *.csv format (columns have sample attributes).
Below you can see how the mapping file has been used.   

For more infromation: [phyloseq](http://joey711.github.io/phyloseq/import-data) 

**Things to be done in QIIME terminal (if required):**
**Important Note 2**: If you have error in loading the biom files stating **JSON or HDF5** then you need to convert it in to a JSON format.  

For this, use the following command within the QIIME terminal and not in R!  

````{r}
# biom convert -i NGTaxMerged.biom -o ngtax_json.biom --table-type "OTU table" --to-json    
```

For more information on the biom format please  [click here](http://biom-format.org/documentation/biom_conversion.html). 

**Important Note 3**: The most recent version of NG-Tax does not have this issue. 

Let's begin:

1] Read the biom and mapping file

From now on, all the commands are for R.  

**NOTE**     
Update to latest version of Microbiome package to use the `read_phyloseq` function. This function can be used for reading other outputs (like .shared and consensus taxonomy files from mothur) into phyloseq object.     


## Read input to phyloseq object

```{r }

# may take anywhere between 30 seconds to 2 or more minutes to create a phyloseq object depending on the size of biom file and your PCs processing strength.

pseq1 <- read_phyloseq(otu.file = "NGTaxMerged_conv.biom", taxonomy.file = NULL, metadata.file = "mappingMerged_edit.csv", type = "biom")

```

## Read the tree file.

Note: requires a package called `ape` and the extension has to be ".tre" and not ".tree" (you can just change the name of the file extension)

```{r}
# Load tree file
library(ape)
treefile_p1 <- read.tree("combinedTree.tre")

```

## Merge into phyloseq object.

```{r}
ps1 <-merge_phyloseq(pseq1,treefile_p1)
# ps1 is the first phyloseq object.

rank_names(ps1) #we check the taxonomic rank information 
datatable(tax_table(ps1)) # the table is interactive you can scrol and search thorugh it for details.

```

Even though NG-Tax removes a lot of noise from your data, some unwanted/spurious OTUs will always remain. The next steps will guide you through the process of understanding the noise levels in your data and provide you with reasoning to eliminate some of it.

**Important Note 4**  

All the things you do with your data from this point on are based on your decision making. The settings of the NG-Tax pipeline that you used to get this data are optimised. However, if you have very noisy data, first re-run your data with a more strict abundance cut-off before trying to remove it yourself.

Always keep track of the filtering steps you performed and make a note of it!

The decision making starts here!
For instance: Do we expect or want to include Choloropast and Mitrochondria related sequences? if NO then filter them out, if yes skip to next step using ps1 as input file.  

**Important Note 5**  

The fact that you picked up these sequences with NG-Tax means that they were relatively abundant, check the confidence of the sequences before you decide to remove any of them, because the relative abundances of the other OTUs in your samples will change when you start to filter manually.

## Filter phyloseq  

```{r}

ps1a <- subset_taxa(ps1,Class!="Chloroplast")

ps1b <- subset_taxa(ps1a,Order!="Mitochondria")

# Second question: Do we expect or want to include the archaeal sequences? if you have used primers which do not  target them, then it is a spurious observation.
#Keep in mind: The fact that you picked up these sequences with NG-Tax means that they were relatively abundant, check the confidence of the sequences before you decide to remove them.
#If you find high abundance/high confidence sequences that in theory should not be there, maybe more things are wrong with your data. Be critical. OR, your primer did pick up these sequences.

ps1 <- subset_taxa(ps1b,Domain!="Archaea")

# We again name it as ps1 to avoid complicating or creating lot of ps objects.

sort(sample_sums(ps1)) #check the number of reads/sample,we can see that one of the samples has only 1867 seqs, normally we would remove it, but because it mock community data, we can check wether this sequencing depth is enough to capture the theoretical composition, so for now we will leave it in. Just pay extra attention to where this sample ends up in downstream analysis.
 

# Nevertheless, in case you want to remove some samples because of low sequencing depth or some other technical reasons you can remove it from the analysis with the following command:
# ps1.sub <-subset_samples(ps1, #phyloseq object
                       #  SampleID !="SampleName") #metadata category name and != mean including all expect "SampleName"

# again we type the name and hit enter
# ps1 <- ps1.sub # this is our naively filtered phyloseq file which can undergo further filtering

# If you dont have anything to filter then continue with ps1 object for rest of the analysis.

```

It is also useful to mark the unidentified OTUs at Doamin and Phyla level. You can also do it at any taxonomic level, especially when you want to plot composition plots.  

```{r}

tax_table(ps1)[tax_table(ps1)[,"Domain"]== NA, "Domain" ] <- "Unidentified_Domain"
tax_table(ps1)[tax_table(ps1)[,"Phylum"]== "p__", "Phylum" ] <- "Unidentified_Phylum"

```

In our Mock Community analysis using data from a Hiseq machine, we don't have any of the aforementioned issues and hence we will continue using "ps1" as our phyloseq object for downstream analysis.

We have the phyloseq object ready for step wise analysis.

# Exploring your sequence data  

## Distribution of the reads over the samples   
For this, we need one extra R package to handle data objects called "data.table". We will then explore our preliminary data. The table is interactive and you can scroll and search the table.  

Let's take a look at the distribution of the reads over the samples

```{r, warning = FALSE, message = FALSE}

library("data.table")
library(ggplot2)
ps1_df= data.table(as(sample_data(ps1), "data.frame"), Reads_per_sample = sample_sums(ps1), keep.rownames = TRUE)
ps1_df_plot = ggplot(ps1_df, aes(Reads_per_sample)) + geom_histogram() + ggtitle("Distribution of reads per sample") + ylab("Sample counts") 

print(ps1_df_plot) #normal plot

ggsave("./Test_Outputfiles/Distribution_of_reads_per_sample.pdf", height = 6, width = 8) # you can create a sub-folder for figures to save all files in location. here, "./Test_Outputfiles/" notice the full stop or punt (in dutch) infornt of slash "./" this tells R to go inside a folder within the exsisting working directory and save the output.

# I include this now for better managing of projects.
```


Some samples at the right have high number of reads. This is a way to see if you have more or less even sequencing depth. Here, the mock communities were seqeucnced at different depths. Don't worry, differences of up to 50x are quite normal.

Now let's check the distribution of the OTUs in our data set.  

```{r, message=FALSE}

# We make a data table with information on the OTUs
ps1.dt.taxa = data.table(tax_table(ps1),OTUabundance = taxa_sums(ps1),OTU = taxa_names(ps1))
ps1.dt.tax.plot <- ggplot(ps1.dt.taxa, aes(OTUabundance)) + geom_histogram() + ggtitle("Histogram of OTU (unique sequence) counts") + theme_bw()
print(ps1.dt.tax.plot)
#write.table(ps1.dt.taxa, "ps1_dt_tax_plot.txt", sep = "\t")
ggsave("./Test_Outputfiles/Histogram of OTU counts.pdf", height = 6, width = 7)

```


We observe a distribution that is skewed to the left side of the plot. This means that we have some OTUs that are repeated > 300.000 times, but a large number of OTUs are repeated < 100.000 (which is of course is still high). However we see that a very large proportion of our OTUs is repeated a lot less. Remember we have 466 OTUs in total. Now it seems that these are close to zero, but let's have a closer look. Only a small proportion of reads is repeated less than 250x  

```{r, message=FALSE}
library(ggplot2)
plot.zoom <- ggplot(ps1.dt.taxa, aes(OTUabundance)) + geom_histogram() + ggtitle("Histogram of Total Counts") + xlim(0, 1000) + ylim (0,50) + theme_bw()
print(plot.zoom)
ggsave("./Test_Outputfiles/histogram of counts_zoomed_0_to_1000.pdf", height = 6, width = 7)

```


If we zoom in even further, we see that only very little OTUs contain less than 20 reads. In real case senario, if your sequencing and OTU identification did not go well you might see a skewed distribution and may indicate the need for further filtering and processing.  


```{r, message=FALSE}
library(ggplot2)
plot.zoom <- ggplot(ps1.dt.taxa, aes(OTUabundance)) + geom_histogram(breaks=seq(0, 20, by =1)) + ggtitle("Histogram of Total Counts") + theme_bw()
print(plot.zoom)
ggsave("./Test_Outputfiles/histogram of counts_zoomed_0_to_20.pdf", height = 6, width = 7)

```

Let's find out what these numbers actually mean with regards to the total amount of data in this set.  

## Read summary

```{r}
#total number of reads in the dataset
reads_per_OTU <- taxa_sums(ps1)
print(sum(reads_per_OTU))
# we have a total of 5251399 reads

#We saw in the last graph that only a small fraction of the OTUs consist of less than 10 reads, so how much OTUs are this and how many reads do they contain?

print(length(reads_per_OTU[reads_per_OTU < 10]))
# there are 109 OTus that contain less than 10 reads
print(sum(reads_per_OTU[reads_per_OTU < 10]))
# more importantly, these OTUs only contain 512 reads
print((sum(reads_per_OTU[reads_per_OTU < 10])/sum(reads_per_OTU))*100)
# which is only 0.00974% of the data, not bad right?

# To put this into context; out of the 466 OTUs, a 109 OTUs contain less than 10 reads, which is:
print((109/466)*100)
# 23.4% of the OTUs. This sounds like a large number, but remember; they only contain 0.00974% of the total data! This means that OTUs with a lower confidence (ie repeated 10 times or less are only a very small part of this dataset). Check this distribution with your own dataset.

#Important!: From this we can conclude that a very small part of your data can have a significant effect on your downstream analyses, if you use methods that use OTUs instead of the information that is containd in de sequences, such as Unifrac and phylogenetic diversity.

#Some other other checks that are normally done on sequencing data. You might recognize them from literature
# Check for singletons

ps1.dt.taxa[(OTUabundance <= 0), .N] # no singletons

#check for doubletons
ps1.dt.taxa[(OTUabundance <= 2), .N]

# out of 466, we have 11 doubletons
print((11/466)*100)
print((sum(reads_per_OTU[reads_per_OTU <= 2])/sum(reads_per_OTU))*100)
# only 2.3% of the OTUs are doubletons and they consist of 0.000418% of the data

```


What we do now is important and also needs to be documented for reproducibility. We plot the cumulative sum of taxa to make decisions for filtering.    

**Important Note 6** :   
As is clear from the former paragraph, in most instances with NG-Tax there will not be any need to filter out OTUs!! This is just for validation of the data. Remember, if you start filtering afterwards you create a bias, because the following filtering steps ignore the distribution of your data among the samples!!  
Based on how the mock community data looks like, you can don't need to do any filtering. However, if your data is problematic We will discuss some things you can do in later sections using examples.  

You can filter by abundance ie. OTUs that contain less than a set number of reads are discarded. You can plot the OTU distribution.     

## Filtering Threshold, Minimum Total Counts   

```{r }
library(ggplot2)
ps1.cumsum = ps1.dt.taxa[, .N, by = OTUabundance]
setkey(ps1.cumsum, OTUabundance)
ps1.cumsum[, CumSum := cumsum(N)]
# Define the plot
ps1.cumsum.plot = ggplot(ps1.cumsum, aes(OTUabundance, CumSum)) + 
  geom_point() +
  xlab("Filtering Threshold, Minimum Total Counts") +
  ylab("OTUs Filtered") +
  ggtitle("OTUs that would be filtered vs. the minimum count threshold") + theme_bw()

print(ps1.cumsum.plot)

ggsave("./Test_Outputfiles/OTUs that would be filtered vs the minimum count threshold.pdf", height = 6, width = 7)

```


Zoom in on the OTUs that contain <100 reads.  
This will give an idea about the loss of OTUs when you use a certain count threshold. 


```{r}
library(ggplot2)
ps1.cumsum.plot.zoom <- ps1.cumsum.plot + xlim(0, 100) + theme_bw() #this will give an idea of the potential loss in otus you might expect in our dataset.

print(ps1.cumsum.plot.zoom) 

ggsave("./Test_Outputfiles/OTUs that would be filtered vs the minimum count threshold_zoom_0_to_100.pdf", height = 6, width = 7)

```


In the next plot we can see the variance in the reads/OTU. These plots might be informative if you have very skewed data and see patterns. Here, however we see no clear patterns. We also know that the data represents the theoretical MCs quite good, so no need to draw any conclusions. However, check whether your own data deviates from this dataset.

## Variance

```{r}
library(ggplot2)
Variance.plot <- qplot(log10(apply(otu_table(ps1), 1, var)), xlab = "log10(variance)", main = "Variance in OTUs")
print(Variance.plot)
ggsave("./Test_Outputfiles/OTU_distribution_NG-Tax.pdf", height = 6, width = 7)

```


# Alpha diversity calculations  

Note: Some alpha diversity metrics such as ACE are richness estimators, which also consider rare OTUs to estimate the total richness. However if all these rare OTUs are really just error (and the vast majority of them are) then these estimates are meaningless anyway. Thus using NG-Tax, phyloseq will give an error and will ask for "unfiltered data'. We will use the `plot_richness` function from the `phyloseq` package for alpha diversity analysis. However, it is important that you document this and be aware that you results will be conservative. However, if you do use unfiltered data your answers will be useless and based on the number of reads you have per sample (as you know this depends on the barcode and the amount of reads you ordered, not on your sample composition). Also, as already explained; the number of OTUs and the amount of data/reads they contain is very skewed. That is why we advise phylogenetic diversity for all diversity analyses, unless other metrics give similar results.  

The real composition of the MCs is as follows, the real values will depend slightly on the sequenced region (V4 is more stable so will contain less OTUs when sequenced, while V5-V6 will result in more; if things are done properly):

MC1: 17 species, equimolar
MC2: 55 species, equimolar
MC3: the same 55 species as MC2, but distributed differently (lower evenness=lower diversity)
MC4: 43 species, with some at 0.1,0.01 and 0.001%. Again the same type of species as in the other MCs

Try to figure out what kind of pattern of the MCs you expect based on this information.   

## Phyogenetic diversity  

Phylogenetic diversity is calculated using the `picante` package.  

```{r, fig.height= 6, fig.width=12, message=FALSE}

my_colors <- c("#CBD588", "#5F7FC7", "orange","#DA5724", "#508578", "#CD9BCD", "#AD6F3B", "#673770","#D14285", "#652926", "#C84248", "#8569D5", "#5E738F","#D1A33D", "#8A7C64", "#599861", "steelblue" )

# install.packages("picante",repos="http://R-Forge.R-project.org") 
# library(picante)
library(picante)
otu_table_ps1 <- as.data.frame(ps1@otu_table)
metadata_table_ps1  <- as.data.frame(ps1@sam_data)

df.pd <- pd(t(otu_table_ps1), treefile_p1,include.root=F) # t(ou_table) transposes the table for use in picante and the tre file comes from the first code chunck we used to read tree file (see making a phyloseq object section).


datatable(df.pd)
# now we need to plot PD
# check above how to get the metadata file from phyloseq object.
# We will add the results of PD to this file and then plot.
metadata_table_ps1$Phyogenetic_diversity <- df.pd$PD 

plot.pd <- ggplot(metadata_table_ps1, aes(MC_type2, Phyogenetic_diversity)) + geom_boxplot(aes(fill = Region)) + geom_point(size = 2) + theme(axis.text.x = element_text(size=14, angle = 90)) + scale_fill_manual(values = c("#CBD588", "#5F7FC7", "orange","#DA5724", "#508578")) + theme_bw()
print(plot.pd)

```

We can see that the seqeunced phylogenetic diversity very accurately reproduces the theoretical diversity.

For the convenience of using other metrics, we will show the plot for several options available in Phyloseq and Microbiome packages.  

## Non-Phylogenetic metrics

```{r,fig.height= 6, fig.width=20}
#plot the diversity using different metrics
p <- plot_richness(ps1, "Mock_type", measures = c("Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson", "Fisher"))
p <- p + geom_boxplot(aes(fill = "Mock_type")) + scale_fill_manual(values = c("#CBD588", "#5F7FC7", "orange","#DA5724", "#508578"))
print(p)

#plot the diversity using different metrics and color the points by different variable region, the plot also contains the expected values and sequenced values to compare what you sequenced to what it is supposed to be. Check with your own expectations.
p <- plot_richness(ps1, "MC_type2", measures = c("Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson", "Fisher"))
p <- p + geom_point(aes(color = Region)) + theme_bw()
print(p)

```

To investigate in more detail, we will sepearte our data based on 16S rRNA gene hypervariable region and plot the alpha diversity metrics.  

1. Only the v4 region.  

```{r, fig.height= 6, fig.width=20}
#to plot the regions separately (because we saw that they give slightly different results)
#filter out the samples based on region

ps1.V4 <- subset_samples(ps1, Region=="V4")
plot.v4.Adiv <- plot_richness(ps1.V4, "MC_type2", measures = c("Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson", "Fisher"))
plot.v4.Adiv <- plot.v4.Adiv + geom_point(aes(color = Mock_type)) + theme_bw()
print(plot.v4.Adiv)

```

2. Only the V5-V6 region.  

```{r, fig.height= 6, fig.width=20}

ps1.V5V6 <- subset_samples(ps1, Region=="V5-V6")

plot.V5V6.Adiv <- plot_richness(ps1.V5V6, "MC_type2", measures = c("Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson", "Fisher"))
plot.V5V6.Adiv <- plot.V5V6.Adiv + geom_point(aes(color = Mock_type))

```

As you can see only Simpson/invSimpson reproduces the biological order of the theoretical MCs (ie perfect data without sequencing/PCR error). Therefore, most of thes metrics don't show the underlying biological conclusions, but are based on other (non-biological) parameters. UNLESS de difference between your biological samples/groups was very large to begin with (such ~3x higher richness as in MC1 compared to the other MCs).

However, when we use a metric such as phylogenetic diversity or Faith's diversity index we reproduce the biological order of the theoretical samples, with both regions. Therefore this metric is prefered. 

**Important note 6** :    
Always challenge your data: Use phylogenetic diversity, check the other metrics and see in what ways they give similar results (or not!) and try to deduce why you observe these things.  

## Others   
For more diversity indices please refer to [Microbiome Package](http://microbiome.github.io/microbiome/Diversity.html)

# Test of significance

Next we can test whether there are significant differences between the MC types


```{r}

# We can check whether there  are any significant differences in alpha diversity between the sample groups we are interested in.
ps1.adiv <- estimate_richness(ps1, measures = c("Chao1", "Shannon", "Observed", "InvSimpson"))

ps1.metadata <- as(sample_data(ps1), "data.frame")
head(ps1.metadata)

#We add the columns with the alpha-div indices from ps3.adiv to ps3.adiv.metadata where all info including metadata is now available.
ps1.metadata$Observed <- ps1.adiv$Observed 
ps1.metadata$Shannon <- ps1.adiv$Shannon
ps1.metadata$InvSimpson <- ps1.adiv$InvSimpson
ps1.metadata$Phyogenetic_diversity <- df.pd$PD # we also add Phylogenetic diversity values from previous code for analysis.

colnames(ps1.metadata) #check the last three coloumns will be the alpha diversity indices

# now we do Kruskal-Wallis (Why? please read the difference between parameteric and non-parametric tests)
# Compare the difference between MCs using Shannons diversity index
kruskal.shannon_type <- kruskal.test(ps1.metadata$Shannon ~ ps1.metadata$Mock_type)
print(kruskal.shannon_type)

#Compare difference between MCs using InverseSimpson
kruskal.InvSimpson_type <- kruskal.test(ps1.metadata$InvSimpson ~ ps1.metadata$Mock_type)
print(kruskal.InvSimpson_type)

#Compare difference between MCs using richness
kruskal.obs <- kruskal.test(ps1.metadata$Observed ~ ps1.metadata$Mock_type)
print(kruskal.obs)

#Compare difference between MCs using richness
kruskal.pd <- kruskal.test(ps1.metadata$Phyogenetic_diversity ~ ps1.metadata$Mock_type)
print(kruskal.pd)

#we can also compare two groups
#with adjustmen for multiple testing
pairwise.wilcox.test(ps1.metadata$Phyogenetic_diversity, ps1.metadata$Mock_type, p.adj = "BH")
pairwise.wilcox.test(ps1.metadata$Phyogenetic_diversity, ps1.metadata$Facet, p.adj = "BH")

```


# Plot composition

**Important note 7** :   
There are different options for doing all the following analyses. You can use the separate OTUs for finer detail. Just remember they are unique sequences, not necessarily 'species'. For this purpose, you need to use the ps1 object and then do:

## Barplot composition  


```{r, fig.height= 6, fig.width=20, warning=FALSE, message= FALSE}

ps1.com <- ps1 # create a new pseq object
# We need to set Palette
taxic <- as.data.frame(ps1.com@tax_table)  # this will help in setting large color options

colourCount = length(unique(taxic$Family))  #define number of variable colors based on number of Family (change the level accordingly to phylum/class/order)
getPalette = colorRampPalette(brewer.pal(12, "Paired"))  # change the palette as well as the number of colors will change according to palette.

# now edit the unclassified taxa
tax_table(ps1.com)[tax_table(ps1.com)[, "Family"] == "f__", "Family"] <- "f__Unclassified family"
# We will also remove the 'f__' patterns for cleaner labels
tax_table(ps1.com)[, colnames(tax_table(ps1.com))] <- gsub(tax_table(ps1.com)[, 
    colnames(tax_table(ps1.com))], pattern = "[a-z]__", replacement = "")

otu.df <- as.data.frame(otu_table(ps1.com))  # make a dataframe for OTU information.
# head(otu.df) # check the rows and columns

taxic$OTU <- row.names.data.frame(otu.df)  # Add the OTU ids from OTU table into the taxa table at the end.
colnames(taxic)  # You can see that we now have extra taxonomy levels.

library(knitr)
head(kable(taxic))  # check the table.

taxmat <- as.matrix(taxic)  # convert it into a matrix.
new.tax <- tax_table(taxmat)  # convert into phyloseq compaitble file.
tax_table(ps1.com) <- new.tax  # incroporate into phyloseq Object


# it would be nice to have the Taxonomic names in italics.
# for that we set this
guide_italics <- guides(fill = guide_legend(label.theme = element_text(size = 15, 
    face = "italic", colour = "Black", angle = 0)))


## Now we need to plot at family level, We can do it as follows:

# first remove the phy_tree

ps1.com@phy_tree <- NULL

# Second merge at family level

ps1.com.fam <- aggregate_taxa(ps1.com, "Family")


plot.composition.COuntAbun <- plot_composition(ps1.com.fam) + theme(legend.position = "bottom") + 
    scale_fill_manual(values = getPalette(colourCount)) + theme_bw() + 
    theme(axis.text.x = element_text(angle = 90)) + 
  ggtitle("Relative abundance") + guide_italics 
  
plot.composition.COuntAbun
ggsave("./Test_Outputfiles/Family_barplot_CountAbundance.pdf", height = 6, width = 8)


```


This plot is based on the reads/sample. You can see the reads are not evenly distributed over the samples, nevertheless their overall composition seems to be the same. The only thing that is different is the scaling. You don't need any other normalisation alogorithms. To check this in the next step we plot the relative abundance.


Make it relative abundance

```{r, fig.height= 6, fig.width=20, warning=FALSE, message= FALSE}

# the previous pseq object ps1.com.fam is only counts.

# Use traqnsform function of microbiome to convert it to rel abun.

ps1.com.fam.rel <- microbiome::transform(ps1.com.fam, "compositional")

plot.composition.relAbun <- plot_composition(ps1.com.fam.rel) + theme(legend.position = "bottom") + 
    scale_fill_manual(values = getPalette(colourCount)) + theme_bw() + 
    theme(axis.text.x = element_text(angle = 90)) + 
  ggtitle("Relative abundance") + guide_italics 
  
plot.composition.relAbun


ggsave("./Test_Outputfiles/Family_barplot_RelAbundance.pdf", height = 6, width = 8)


```

## Heatmap log10 tranformed  

The actual transform is Using log10(1 + x) since there are zeros in OTU table    

```{r, fig.height= 8, fig.width=16, warning=T, message= FALSE}

# do the same as for barplot. If you want it at family level merege at that level. Then transform and then use it as input to plot_composition function.

ps1.com.fam.log <- microbiome::transform(ps1.com.fam, "log10")

plot.composition.log.heatmap <- plot_composition(ps1.com.fam.log, plot.type = "heatmap") + theme(legend.position = "bottom") + 
    theme_bw() + theme(axis.text.x = element_text(angle = 90)) + ggtitle("Heatmap Log10(1+x) tranformed") + 
    theme(axis.text = element_text(face = "italic"))

plot.composition.log.heatmap <- plot.composition.log.heatmap + scale_fill_continuous(high = "#014e6b", 
    low = "#caebf7")

print(plot.composition.log.heatmap)

ggsave("./Test_Outputfiles/Family_Heatmap_logAbundance.pdf", height = 6, width = 8)

```


for more information [Microbiome tutorial](http://microbiome.github.io/microbiome/Composition.html)   


In the legends of these composition plots now consists of the taxonomic labels.   

# Beta diversity metrics

This approach, together with alpha-diversity is very sensitive  to spurios otus, lots of zeros and skewed distribution of counts. Hence, different people have different preferences, such as rarefaction or normalisation algorithms. Rarefaction is a common treatment, however for NG-Tax data this is unneccesary even though the sequencing depth ranges from 1867 to 315845 reads per sample, therefore we can just transform the data into relative abundance.
In case you want to still rarefy your data, (REMEMBER! you throw away >90% of your data!) below are the commands for different ordination methods.

For more information:

[Waste Not, Want Not: Why Rarefying Microbiome Data Is Inadmissible](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003531).  

[Normalisation and data transformation](https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-017-0237-y).  

[What is Constrained and Unconstrained Ordination](http://www.davidzeleny.net/anadat-r/doku.php/en:ordination).  

## Unconstrained

### Without rarefaction  

```{r, fig.height= 8, fig.width=14}

ps1.rel <- transform(ps1, "relative.abundance")

set.seed(49275)  #set seed for reproducible rooting of the tree
ordu.wt.uni = ordinate(ps1.rel, "PCoA", "unifrac", weighted = TRUE)

scree.plot <- plot_scree(ordu.wt.uni, "Check for importance of axis in Scree plot for MCs, UniFrac/PCoA")
print(scree.plot)

wt.unifrac <- plot_ordination(ps1.rel, ordu.wt.uni, 
                              color = "MC_type2", 
                              shape = "Region")

wt.unifrac <- wt.unifrac + scale_fill_manual(values = c("#CBD588", 
    "#5F7FC7", "orange", "#DA5724", "#508578")) + 
  ggtitle("Weighted UniFrac relative abundance") + 
  geom_point(size = 3)

print(wt.unifrac)

set.seed(475)  #set seed for reproducible rooting of the tree
ordu.unwt.uni = ordinate(ps1.rel, "PCoA", "unifrac", weighted = F)
unwt.unifrac <- plot_ordination(ps1.rel, ordu.unwt.uni, 
                                color = "MC_type2", 
                                shape = "Region") + 
  ggtitle("Unweighted UniFrac relative abundance") + 
  geom_point(size = 3)

print(unwt.unifrac)

# Bray Curtis dissimilarity (purely OTU based, doesn't take
# the sequence of the OTUs into account)

ordu.bray = ordinate(ps1.rel, "PCoA", "bray", weighted = F)
bray <- plot_ordination(ps1.rel, ordu.bray, 
                        color = "Mock_type", 
                        shape = "Region")

bray <- bray + scale_fill_manual(values = c("#CBD588", "#5F7FC7", 
    "orange", "#DA5724", "#508578")) + 
  ggtitle("Bray-Curtis relative abundance V4 and V5-V6") + 
    geom_point(size = 3) + theme_bw()

print(bray)

```

### With rarefaction  

```{r}
#with rarefaction

set.seed(09809) # alway set a random number seed for reproducibility of the rarefaction
ps1.rar <- rarefy_even_depth(ps1)
head(sample_sums(ps1.rar)) # check whether it is rarefied

set.seed(999)
ordu.wt.uni = ordinate(ps1.rar, "PCoA", "unifrac", weighted=TRUE)
wt.unifrac.rar <- plot_ordination(ps1.rar, ordu.wt.uni, 
                                  color="MC_type2", 
                                  shape="Region") 

wt.unifrac.rar <- wt.unifrac.rar + scale_fill_manual(values = c("MC_type2")) + 
  ggtitle("Weighted UniFrac rarefied to 1867 sequences per sample") + 
  geom_point(size = 3)

print(wt.unifrac.rar)


set.seed(949)
ordu.unwt.uni = ordinate(ps1.rar, "PCoA", "unifrac", weighted=F)
unwt.unifrac.rare <- plot_ordination(ps1.rar, ordu.unwt.uni, color="MC_type2", shape="Region") + 
  ggtitle("Unweighted UniFrac rarefied to 1867 sequences per sample") + 
  geom_point(size = 3)

print(unwt.unifrac.rare)

#Bray Curtis dissimilarity (purely OTU based, doesn't take the sequence of the OTUs into account)

ordu.bray = ordinate(ps1.rar, "PCoA", "bray", weighted=F)
bray.rar <- plot_ordination(ps1.rel, ordu.bray, color="Mock_type", shape="Region")
bray.rar <- bray + scale_fill_manual(values = c("#CBD588", "#5F7FC7", "orange","#DA5724", "#508578")) + 
  ggtitle("Bray-Curtis rarefied to 1867 sequences per sample, region V4 and V5-V6") + 
  geom_point(size = 3)

print(bray.rar)

```

You can see rarefaction is unneccesary, furthermore it seems that separation of the MCs is even better without rarefaction as you retain minor signals.

### Bray-Curtis based dissimilarity using separate regions

Because Bray-Curtis based dissimilarity seems to differentiate between the two regions instead of the biological difference (i.e. MC type) we can take look at a single region.

```{r}
ps1V4.rel <- transform_sample_counts(ps1.V4, function(x) x / sum(x) )

ordu.brayV4 = ordinate(ps1V4.rel, "PCoA", "bray")
bray <- plot_ordination(ps1V4.rel, ordu.brayV4, 
                        color="MC_type2", 
                        shape="Region")
bray <- bray + scale_fill_manual(values = c("#CBD588", "#5F7FC7", "orange","#DA5724", "#508578")) + 
  ggtitle("Bray-Curtis relative abundance V4") + 
  geom_point(size = 3)

print(bray)

ps1.V5V6.rel <- transform_sample_counts(ps1.V5V6, function(x) x / sum(x) )

ordu.brayV5V6 = ordinate(ps1.V5V6.rel, "PCoA", "bray")
bray <- plot_ordination(ps1.V5V6.rel, ordu.brayV5V6, 
                        color="MC_type2", 
                        shape="Shape")

bray <- bray + scale_fill_manual(values = c("#CBD588", "#5F7FC7", "orange","#DA5724", "#508578")) + 
  ggtitle("Bray-Curtis relative abundance V5V6") + 
  geom_point(size = 3) + theme_bw()

print(bray)

```

From these plots we can conclude that methods that use information contained in the sequence, like Unifrac, are more powerful and less dependent on small (sequencing/PCR) errors.    

More on [Adonis test](http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/adonis.html) or [GUSTA ME](https://sites.google.com/site/mb3gustame/hypothesis-tests/manova/npmanova)    


```{r}

metadf <- data.frame(sample_data(ps1.V5V6.rel))

set.seed(28567)
unifrac.dist <- UniFrac(ps1.V5V6.rel, 
                        weighted = TRUE, 
                        normalized = TRUE,  
                        parallel = FALSE, 
                        fast = TRUE)

# Adonis test
adonis(unifrac.dist ~ Facet, data = metadf)

```

Facet has a significant effect on the community.  
But is it really possible or is it a chance event.  
Check [beta dispersity](http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/betadisper.html)  

```{r}

ps.disper <- betadisper(unifrac.dist, metadf$Facet)
permutest(ps.disper)

```

The dispersity is not significant means our previous adonis results are good.  

## Constrained

[Partial] Constrained Analysis of Principal Coordinates (CAPSCALE) or distance-based RDA, via capscale. See capscale.phyloseq for more details. In particular, a formula argument must be provided.  

```{r, fig.height= 8, fig.width=14}
# CAP ordinate using Bray Curtis dissimilarity only looking at V4
set.seed(23234) 
ps1V4.rel_bray <- phyloseq::distance(ps1V4.rel, method = "bray") # CAP ordinate 
cap_ord <- ordinate(physeq = ps1V4.rel,  
                    method = "CAP", 
                    distance = ps1V4.rel_bray, 
                    formula = ~ Mock_type)

# chech which asix are explaining how mauch variation

scree.cap <- plot_scree(cap_ord, "Scree Plot for MCs in Constrained Analysis of Principal Coordinates (CAPSCALE)")
print(scree.cap)

# CAP plot 
cap_plot <- plot_ordination(physeq = ps1V4.rel, 
                            ordination = cap_ord, 
                            color = "Mock_type", 
                            shape = "Region",
                            axes = c(1,2)) + 
  geom_point(aes(colour = Mock_type), size = 3) + 
  geom_point(size = 3) +
  scale_color_manual(
    values = c( "#CBD588", "#5F7FC7", "orange","#DA5724", "#508578")) 
cap_plot + ggtitle("CAP_Plot")  + theme_bw()  
ggsave("./Test_Outputfiles/CAP_plot.pdf", height = 8, width = 10)

# Now add the environmental variables as arrows 
arrowmat <- vegan::scores(cap_ord, display = "bp")
# Add labels, make a data.frame 
arrowdf <- data.frame(labels = rownames(arrowmat), arrowmat)
# Define the arrow aesthetic mapping 
arrow_map <- aes(xend = CAP1, 
                 yend = CAP2, 
                 x = 0, y = 0, 
                 shape = NULL, 
                 color = NULL, 
                 label = labels) 
label_map <- aes(x = 1.3 * CAP1, y = 1.3 * CAP2, 
                 shape = NULL, 
                 color = NULL,
                 label = labels)  

arrowhead = arrow(length = unit(0.02, "npc")) 

##now plot the arrow
cap_plot <- cap_plot + geom_segment(mapping = arrow_map, size = .7, 
                        data = arrowdf, color = "black", 
                        arrow = arrowhead) + 
  geom_text(mapping = label_map, size = 4,  
            data = arrowdf, 
            show.legend = TRUE) + ggtitle("CAP_Plot")  + theme_bw() 
print(cap_plot)

ggsave("./Test_Outputfiles/CAP_plot_arrows.pdf", height = 8, width = 10)

#further editing can be done using any of the image processing tools to easily clarify labels.

```

Testing for significance in beta diversity

```{r}
##statistical testing 
set.seed(19743) 
cap_anova <- anova(cap_ord, by="terms", permu=999) # we test the impact of the environmental variable seperately. Kindly check for these functions in the help section on the right side.

print(cap_anova)

set.seed(19773) 
#we see that Mock type has a significant impact on the beta diversity using only region V4. (Remember; for Bray Curtis the sequenced region was more important)  

#testing various factors (increase the permutation for real data) 
anova(cap_ord) ## Global test of the significance of the analysis.

# calculate R squared values

RsquareAdj (cap_ord)

```

Check this link for more possiblities in [ordination analysis](http://cc.oulu.fi/~jarioksa/opetus/metodi/vegantutor.pdf)

# Additional examples

## Utilities/handy commands

```{r}

# selecting only the the OTU_table and saving it as csv to open it in excel
otu_table_ps1 <- as.data.frame(ps1@otu_table)
# For the purpose of this tutorial we use # to avoid this command from running in the report generation. please copy the part after the "# Code:" 

# Code: write.csv(otu_table_ps1, file = "otu_table_ps1.csv", fileEncoding = "UTF-16LE") #for Windows Excel 2007/10

# selecting only the the taxonomy_table and saving it as csv to open it in excel

taxonomy_table_ps1 <- as.data.frame(ps1@tax_table)
# Code : write.csv(taxonomy_table_ps1, file = "taxonomy_table_ps1.csv", fileEncoding = "UTF-16LE") #for Windows Excel 2007/10

# selecting only the the metadata_table and saving it as csv to open it in excel

metadata_table_ps1 <- as.data.frame(ps1@sam_data)
# Code : write.csv(metadata_table_ps1, file = "metadata_table_ps1.csv", fileEncoding = "UTF-16LE") #for Windows Excel 2007/10

# select only a subset of samples_P1
# as an example, only samples and other data for theoretical will be selected from original phyloseq object "ps1"
ps1.subset.theoretical <- subset_samples(ps1, Facet == "Theoretical") # notice the == sign

print(ps1.subset.theoretical)
# you can see that we have only 8 samples and no samples from mock community.

# select only a subset of samples
# as an example, we will now remove all information from theoretical samples from original phyloseq object "ps1"
ps1.subset.no.theoretical <- subset_samples(ps1, Facet != "Theoretical") # notice the != sign

print(ps1.subset.no.theoretical)
# you can see that we have 49 samples and no samples from theoretical.

# get only genus level information
ps1.genus <- tax_glom(ps1, taxrank = "Genus")
ps1.df <- psmelt(ps1.genus)
# Code : write.csv(ps1.df, file='otus_genus_metadata.csv')

```

## Aggregating your OTUs to a specifc taxonomic level  

This is somewhat similar to `summarize_taxa` function in QIIME but this one uses phylogenetic tree for merging OTUs. So much better because the reference databases are not perfect (i.e reads that are close in sequence but for some reason are classified differently will be more separate based on their name than the sequence actually would show).

tax_glom is good but we might also have data where a lot of OTUs are unassigned. In such senarios, we can use tip_glom(), which uses the phylogenetic tree to merge closely related otus.

```{r}
ps1.tip.glom <- tip_glom(ps1, h = 0.04) # h = "X" is an iterative process
# Using a value of 0.04 as the height where the tree should be cut, we get close to the number of genus we expect in our mock community. But again, to get a good feeling for your data play with these settings and see whether it is appropriate for your data.

p.tree <- plot_tree(ps1.tip.glom, 
                    label.tips="taxa_names", 
                    color = "Facet", 
                    title="tree")
print(p.tree)
# ps1.tip.glom can used for comparative analysis at the genus level.

```

## Dendrograms

```{r, warning = FALSE, message = FALSE, fig.height= 6, fig.width=20}
# install ggdendro from CRAN or using the install button on the right panel.
library(ggplot2)
library(ggdendro)
clustering_samples_dendeogram <- hclust(phyloseq::distance(ps1, method="Unifrac"))

dendeogram.plot <- ggdendrogram(clustering_samples_dendeogram, 
                                rotate = FALSE, size = 2) + 
  ggtitle("UniFrac distance based hierarchical clustering") 

print(dendeogram.plot)

ggsave("./Test_Outputfiles/dendrogram.pdf", height = 8, width = 18)

```


## Use of other useful R packages

### Metagenomeseq:   

Information can be found here  

[Metagenomeseq](https://www.bioconductor.org/packages/devel/bioc/vignettes/metagenomeSeq/inst/doc/metagenomeSeq.pdf)  
[Metagenomeseq paper](http://www.nature.com/nmeth/journal/v10/n12/full/nmeth.2658.html)  

Also check the [following website](http://students.brown.edu/seeing-theory/)  

This is another good package that can be used for a variety of analyses. The examples shown here are easy ones and you will need to play around with settings as per your requirements. Also with the legends in the figures. This is just an example without specifics. WE want to show how you can switch between pacakges for various analysis.   


```{r, warning = FALSE, message = FALSE, fig.height= 6, fig.width=20}

library(metagenomeSeq)
# convert phyloseq object "ps1" to "mseq1"

mseq1 <- phyloseq_to_metagenomeSeq(ps1)
# identify and set the variable you want to investigate, in this case it is the mock community type.

Type.community = pData(mseq1)$Facet
heatmapColColors = brewer.pal(12, "Set3")[as.integer(factor(Type.community))] # change Set3 to any color combination you wish. 

# R color brewer options click here https://www.r-bloggers.com/choosing-colour-palettes-part-ii-educated-choices/

heatmapCols = colorRampPalette(brewer.pal(9, "RdBu"))(50) #color for heatmap

plotMRheatmap(obj = mseq1, n = 200, cexRow = 0.4, cexCol = 0.4,
trace = "none", col = heatmapCols, ColSideColors = heatmapColColors)
# there is a small change on how we save the file from this one

pdf("./Test_Outputfiles/heatmap.pdf", height = 8, width = 18) # create an empty file

plotMRheatmap(obj = mseq1, n = 200, 
              cexRow = 0.4, 
              cexCol = 0.4, 
              trace = "none", 
              col = heatmapCols, 
              ColSideColors = heatmapColColors) # plot the figure

title(main = "This is only example figure!!")

dev.off() # close the file and autosave

```

### OTU prevalence

This will help in identifying the distribution of OTus with taxonomic information. This will also help you to evaluate the composition of different groups that you are interested in (such as environment or healthy/disease), while retaining information of indivual samples.

```{r prevalence-plot}
ps1.prev<- ps1

tax_table(ps1.prev)[tax_table(ps1.prev)[,"Family"]== "f__", "Family" ] <- "f__Unclassified Family"
# We will also remove the "f__" patterns for cleaner labels
tax_table(ps1.prev)[,colnames(tax_table(ps1.prev))] <- gsub(tax_table(ps1.prev)[,colnames(tax_table(ps1.prev))],pattern="[a-z]__",replacement="")

p.prev.plot <- plot_taxa_prevalence(ps1.prev, 'Family')

plot(p.prev.plot)

```

# More tutorials   


*You can find the location of ".html files" in sub-folders*   


1. **Core Microbiome** : "R_for_NG_Tax_Sept2017/Bonus tutorials/Core_microbiome_FEMSRevMicro2017"   
  
  
2. **Ecological networks** : "R_for_NG_Tax_Sept2017/Bonus tutorials/Correlation networks"  
   
   
3. **Other_utilities** : "R_for_NG_Tax_Sept2017/Bonus tutorials/Other utilities"  
    *In Other utilities you can find how to normalize or transform you data*    
     
     
4. **Phyloseq_to_LEfSe** : "R_for_NG_Tax_Sept2017/Bonus tutorials/Phyloseq_to_LEfSe"  
    *from phyloseq object get a text file you can use as input for LEfSe galaxy server*   
     
     
5. **RandomForests analysis** : "R_for_NG_Tax_Sept2017/Bonus tutorials/RandomForests analysis"   
  
  
Useful website for ggplot2 basics. eg. how to add p-values in plots, etc. 

[Add P-values and Significance Levels to ggplots](http://www.sthda.com/english/wiki/add-p-values-and-significance-levels-to-ggplots)  

[Publication-ready-plots](http://www.sthda.com/english/wiki/ggpubr-r-package-ggplot2-based-publication-ready-plots)  

We acknowledge the work of and tools created by:  
[Paul J. McMurdie and colleagues](https://github.com/joey711)  
[Leo Lahti](http://antagomir.github.io/)

# References

1) [Phylogenetic Diversity](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2674678/)     



2) [UniFrac](http://aem.asm.org/content/71/12/8228.full)     



3) [General Diversity](http://www2.ib.unicamp.br/profs/thomas/NE002_2011/maio10/Magurran%202004%20c2-4.pdf)     



4) [To rarify or not to rarefy](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003531)   



5) [Microbiome Helper](hhttp://msystems.asm.org/content/2/1/e00127-16)   



6) [Ordinations](http://parfreylab.botany.ubc.ca/pca-pcoa-and-nmds/)  



7) [Phyloseq paper](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061217)    



8) [Phyloseq workflow](https://f1000research.com/articles/5-1492/v1)  



9) [R for Amplicon-Sequencing-Based Microbial-Ecology](https://rdrr.io/cran/RAM/)    



10) [Rhea](https://github.com/Lagkouvardos/Rhea)  


**For more tools check this [website](https://microsud.github.io/Tools-Microbiome-Anlaysis/)**

# Index   

This is useful for beginners and provides a link to which function belongs to which pacakge. If you face issues then you can specifically look at the package websites for more information.  

### Functions :: Package  

#### `read_phyloseq` :: microbiome  
#### `read.tree` :: ape  
#### `merge_phyloseq` :: phyloseq  
#### `subset_taxa` :: phyloseq  
#### `data.table` :: data.table  
#### `ggplot` :: ggplot2  
#### `taxa_sums` :: phyloseq  
#### `qplot` :: ggplot2  
#### `ggsave` :: ggplot2  
#### `pd` :: picante  
#### `plot_richness` :: phyloseq  
#### `estimate_richness` :: phyloseq  
#### `subset_samples` :: phyloseq  
#### `kruskal.test` :: stats  
#### `pairwise.wilcox.test` :: stats  
#### `plot_composition` :: microbiome  
#### `transform` :: microbiome  
#### `ordinate` :: phyloseq  
#### `plot_ordination` :: phyloseq  
#### `rarefy_even_depth` :: phyloseq  
#### `anova` :: stats  
#### `tax_glom` :: phyloseq  
#### `psmelt` :: phyloseq  
#### `hclust` :: stats  
#### `ggdendrogram` :: ggdendro  
#### `phyloseq_to_metagenomeSeq` :: phyloseq  
#### `pData` :: metagenomeseq  
#### `colorRampPalette` :: grDevices  
#### `plotMRheatmap` :: metagenomeseq  
#### `plot_taxa_prevalence` :: microbiome  

```{r}

sessionInfo()

```


